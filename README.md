# ğŸ§  MentHA â€“ Guia de InstalaÃ§Ã£o e ExecuÃ§Ã£o 






<img width="1906" height="902" alt="image" src="https://github.com/user-attachments/assets/1286e3cd-10b3-4e46-bb7a-1e9ac8547f2c" />

## ğŸ”§ Requisitos de Software

- Python 3.11 ou superior  
- Docker e Docker Compose instalados  
- Git instalado  
- Sistema operativo: Linux, macOS ou Windows  

---

## ğŸ—ï¸ Arquitetura Geral do Projeto

O projeto consiste num website construÃ­do com Django, que integra trÃªs aplicaÃ§Ãµes distintas:

- `diario/`: AplicaÃ§Ã£o responsÃ¡vel pelo registo de atividades (integra MentHA COG e MentHA CARE).
- `mentha/`: Website principal do projeto MentHA.
- `protocolo/`: AplicaÃ§Ã£o dedicada Ã  avaliaÃ§Ã£o neuropsicolÃ³gica (MentHA EVAL â€“ "Protocolo MentHA").

### DiretÃ³rio principal:
```
/raiz_do_projeto
â”œâ”€â”€ diario/                  # MentHA COG & CARE
â”œâ”€â”€ mentha/                 # Frontend principal
â”œâ”€â”€ protocolo/              # MentHA EVAL
â”œâ”€â”€ gateway/                # ConfiguraÃ§Ã£o NGINX
â”œâ”€â”€ manage.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile              # Para desenvolvimento
â”œâ”€â”€ Dockerfile.prod         # Para produÃ§Ã£o (Gunicorn)
â”œâ”€â”€ compose.yaml            # Docker Compose (dev)
â”œâ”€â”€ compose.prod.yaml       # Docker Compose (prod)
â”œâ”€â”€ dump_tests.sql          # Dump de testes (dados dummy)
â””â”€â”€ .env                    # VariÃ¡veis de ambiente (dev/prod)
```
---

## ğŸ”€ Ambientes do Projeto

O projeto MentHA Digital estÃ¡ preparado para funcionar em dois ambientes distintos, com infraestruturas adaptadas a cada caso:

---

## ğŸ§ª Ambiente de Desenvolvimento

Este ambiente destina-se a programadores e equipas durante a fase de implementaÃ§Ã£o, testes e validaÃ§Ã£o local da aplicaÃ§Ã£o. Permite um ciclo de desenvolvimento rÃ¡pido e seguro, com dados anÃ³nimos, hot reload e isolamento completo da produÃ§Ã£o.

### ğŸ³ Arquitetura e ServiÃ§os Docker

O ambiente Ã© orquestrado atravÃ©s do ficheiro `compose.yaml`, que define trÃªs serviÃ§os principais que trabalham em conjunto para simular o funcionamento completo da aplicaÃ§Ã£o:

1. **dbpostgresql**  
   - ServiÃ§o responsÃ¡vel pela execuÃ§Ã£o da base de dados PostgreSQL.  
   - Utiliza a imagem oficial `postgres:12.9`.  
   - Os dados sÃ£o armazenados num volume persistente Docker chamado `postgres_data`, garantindo persistÃªncia entre reinÃ­cios.

2. **dbpostgresql_init**  
   - ServiÃ§o temporÃ¡rio responsÃ¡vel por importar automaticamente o dump de dados de teste (`dump_tests.sql`) para a base de dados.  
   - Usa a mesma imagem oficial `postgres:12.9`.  
   - Monta o ficheiro `dump_tests.sql` do sistema local para dentro do container, permitindo inicializaÃ§Ã£o com dados anÃ³nimos.

3. **web**  
   - ServiÃ§o principal que executa a aplicaÃ§Ã£o Django.  
   - ConstrÃ³i a imagem localmente com base no `Dockerfile`.  
   - Aplica automaticamente todas as migraÃ§Ãµes para manter o esquema da base de dados atualizado.  
   - Inicia o servidor de desenvolvimento Django (`runserver`) com suporte a hot reload, facilitando um desenvolvimento Ã¡gil.

### ğŸ§  Funcionalidades Adicionais

- **Live Reload (Hot Reload):**  
  O cÃ³digo local estÃ¡ ligado ao container via volume (`.:/app`). Sempre que alteras ficheiros, o servidor Django reinicia automaticamente, permitindo visualizar as mudanÃ§as em tempo real, sem necessidade de reiniciar manualmente.

- **VariÃ¡veis de Ambiente:**  
  Todas as configuraÃ§Ãµes especÃ­ficas do ambiente estÃ£o definidas no ficheiro `.env`, separado do cÃ³digo-fonte. Isto facilita a alteraÃ§Ã£o de dados sensÃ­veis sem comprometer o cÃ³digo.

- **Isolamento da ProduÃ§Ã£o:**  
  O ambiente utiliza um dump de dados anÃ³nimos (`dump_tests.sql`), garantindo que os testes locais nÃ£o interferem nem comprometem dados reais de produÃ§Ã£o.

- **Debugging Simplificado:**  
  Logs detalhados e compatibilidade com ferramentas como o VSCode Debugger permitem uma deteÃ§Ã£o e resoluÃ§Ã£o de erros mais eficiente.


---

## ğŸš€ Ambiente de ProduÃ§Ã£o

Este ambiente corresponde Ã  infraestrutura utilizada para o deploy real da aplicaÃ§Ã£o, disponÃ­vel ao pÃºblico. O foco principal Ã© garantir **seguranÃ§a**, **estabilidade**, **performance** e **escalabilidade** para o sistema em produÃ§Ã£o.

### ğŸ—ï¸ VisÃ£o Geral

O ambiente de produÃ§Ã£o Ã© uma configuraÃ§Ã£o mais robusta e otimizada, que inclui:

- ExecuÃ§Ã£o da aplicaÃ§Ã£o Django com um servidor WSGI profissional (Gunicorn) para melhor desempenho e gestÃ£o de mÃºltiplos pedidos simultÃ¢neos.
- UtilizaÃ§Ã£o de um **reverse proxy** (NGINX) containerizado, que serve ficheiros estÃ¡ticos e media de forma eficiente, alÃ©m de proteger e otimizar as comunicaÃ§Ãµes HTTP.
- Base de dados PostgreSQL com armazenamento persistente e saudÃ¡vel.
- ConfiguraÃ§Ãµes especÃ­ficas de ambiente que garantem a separaÃ§Ã£o total da lÃ³gica e dados de desenvolvimento.

### ğŸ³ Docker & OrquestraÃ§Ã£o

O ambiente Ã© gerido pelo ficheiro `compose.prod.yaml`, que define trÃªs serviÃ§os essenciais:

1. **dbpostgresql**  
   - Container da base de dados PostgreSQL, responsÃ¡vel por armazenar todos os dados da aplicaÃ§Ã£o.  
   - Usa um volume Docker persistente para garantir que os dados se mantÃªm seguros entre reinÃ­cios e atualizaÃ§Ãµes do container.  
   - Inclui um mecanismo de healthcheck para monitorar a disponibilidade do serviÃ§o.

2. **web**  
   - ServiÃ§o principal que executa a aplicaÃ§Ã£o Django utilizando o servidor **Gunicorn**, um servidor WSGI leve e eficiente, indicado para produÃ§Ã£o.  
   - Recebe as requisiÃ§Ãµes encaminhadas pelo NGINX e responde com conteÃºdos dinÃ¢micos da aplicaÃ§Ã£o.  
   - Aplica migraÃ§Ãµes e configuraÃ§Ãµes otimizadas para o ambiente de produÃ§Ã£o.  
   - NÃ£o expÃµe funcionalidades de hot reload, garantindo estabilidade.

3. **nginx**  
   - Reverse proxy containerizado que atua como intermediÃ¡rio entre os clientes e o serviÃ§o Django.  
   - Serve diretamente ficheiros estÃ¡ticos (`/static/`) e media (`/media/`) para otimizar a entrega de conteÃºdo e reduzir carga no servidor de aplicaÃ§Ã£o.  
   - Aplica headers de seguranÃ§a importantes (ex: Content Security Policy, X-Frame-Options) e compressÃ£o (gzip) para melhorar performance e seguranÃ§a.  
   - Encaminha requisiÃ§Ãµes HTTP para o serviÃ§o `web` (Gunicorn), mantendo a arquitetura limpa e modular.  

### ğŸ” SeguranÃ§a e Boas PrÃ¡ticas

Para garantir a seguranÃ§a da aplicaÃ§Ã£o em produÃ§Ã£o, especialmente em relaÃ§Ã£o Ã s credenciais e dados sensÃ­veis, adotamos as seguintes prÃ¡ticas:

- **VariÃ¡veis de Ambiente para ConfiguraÃ§Ãµes SensÃ­veis**  
  As informaÃ§Ãµes confidenciais, como a `SECRET_KEY` do Django (usada para criptografia interna e proteÃ§Ã£o da sessÃ£o), as credenciais da base de dados, e outras configuraÃ§Ãµes crÃ­ticas, sÃ£o armazenadas exclusivamente em variÃ¡veis de ambiente definidas num ficheiro `.env` no servidor de produÃ§Ã£o.  
  Isto evita que estas chaves sejam incluÃ­das diretamente no cÃ³digo-fonte ou no repositÃ³rio Git, protegendo-as de acessos nÃ£o autorizados e facilitando a sua atualizaÃ§Ã£o sem necessidade de alterar o cÃ³digo.

- **Camada de proteÃ§Ã£o via NGINX**  
  O NGINX funciona como reverse proxy e firewall, filtrando requisiÃ§Ãµes maliciosas, aplicando cabeÃ§alhos de seguranÃ§a HTTP e servindo conteÃºdos estÃ¡ticos, reduzindo a exposiÃ§Ã£o da aplicaÃ§Ã£o e melhorando o desempenho.

- **Servidor WSGI profissional (Gunicorn)**  
  O Gunicorn oferece uma gestÃ£o eficiente das conexÃµes, permitindo lidar com mÃºltiplos pedidos simultÃ¢neos, garantindo estabilidade e escalabilidade em produÃ§Ã£o.

---

## ğŸ” CI/CD com GitHub Actions

A infraestrutura do projeto estÃ¡ totalmente integrada num pipeline automatizado de CI/CD (Continuous Integration / Continuous Deployment) usando o GitHub Actions. Isto permite que, sempre que um cÃ³digo novo Ã© enviado para o repositÃ³rio (push para a branch `main`), todo o processo de testes e deployment seja executado de forma automÃ¡tica e controlada, garantindo qualidade e rapidez.

### Fluxo do Workflow `deploy.yml`

1. **Fase de Testes (CI)**
   - Cada vez que ocorre um push para a branch principal (`main`), o GitHub Actions inicia uma pipeline de testes.
   - Nesta fase, Ã© criado um ambiente isolado com um container PostgreSQL temporÃ¡rio (`mentha_test`) para simular a base de dados durante os testes.
   - A aplicaÃ§Ã£o Django executa os seus testes automatizados, validando que todas as funcionalidades principais estÃ£o corretas e que nÃ£o existem regressÃµes.
   - Apenas se todos os testes forem aprovados, o workflow avanÃ§a para a prÃ³xima fase.

2. **Fase de Deploy (CD)**
   - Depois dos testes serem bem sucedidos, a pipeline inicia o deploy automÃ¡tico da aplicaÃ§Ã£o para o servidor remoto.
   - Os ficheiros do projeto sÃ£o copiados via SCP (Secure Copy Protocol) para o diretÃ³rio do servidor destinado ao projeto.
   - O ficheiro `.env` Ã© gerado dinamicamente no servidor, utilizando segredos (como chaves secretas e credenciais) guardados em seguranÃ§a no GitHub Secrets, garantindo que informaÃ§Ãµes sensÃ­veis nunca ficam expostas no cÃ³digo-fonte pÃºblico.
   - O workflow executa comandos SSH no servidor para:
     - Parar quaisquer serviÃ§os Docker em execuÃ§Ã£o (`docker-compose -f compose.prod.yaml down`), garantindo uma atualizaÃ§Ã£o limpa.
     - Recriar e iniciar os serviÃ§os em modo destacado, reconstruindo as imagens se necessÃ¡rio (`docker-compose -f compose.prod.yaml up -d --build`).
     - Executar a coleta dos ficheiros estÃ¡ticos da aplicaÃ§Ã£o Django (`python manage.py collectstatic --noinput`), preparando-os para serem servidos pelo NGINX.

### BenefÃ­cios deste CI/CD automatizado

- **AutomaÃ§Ã£o total:** O processo de testes, build e deploy ocorre sem intervenÃ§Ã£o manual, reduzindo erros humanos.
- **SeguranÃ§a reforÃ§ada:** As credenciais e segredos ficam guardados de forma segura no GitHub e nunca no repositÃ³rio.
- **Velocidade e fiabilidade:** Permite lanÃ§ar atualizaÃ§Ãµes rapidamente com menor risco de falhas em produÃ§Ã£o.
- **Isolamento dos ambientes:** Os testes correm num ambiente separado, evitando interferÃªncia nos dados reais.

---

## ğŸ—ƒï¸ Bases de Dados 

### ğŸ§ª Ambiente de Testes

O ambiente de testes utiliza a base de dados definida no ficheiro `dump_tests.sql`, localizado na raiz do projeto. Este ficheiro contÃ©m dados **anÃ³nimos ou simulados**, prÃ³prios para desenvolvimento, debugging e testes.

#### âœ… Importar dump de testes

Para carregar um novo dump de testes no ambiente de desenvolvimento:

1. **Substitui** o ficheiro `dump_tests.sql` na raiz do projeto.
2. **Confirma** que estÃ¡ codificado em `UTF-8` **sem BOM** (sem Byte Order Mark).
3. **Reinicia os serviÃ§os Docker** com remoÃ§Ã£o dos volumes para forÃ§ar a importaÃ§Ã£o:

```bash
# Apaga volumes antigos e forÃ§a importaÃ§Ã£o do novo dump
docker-compose down -v
docker-compose up --build
```
O serviÃ§o dbpostgresql_init irÃ¡ executar automaticamente o psql -f dump_tests.sql.

#### ğŸ“¤ Exportar novo dump de testes

Caso queiras gerar um novo ficheiro `dump_tests.sql` a partir da base de dados atual (por exemplo, para partilhar com colegas), segue os passos abaixo:

```bash
docker exec dbpostgresql pg_dump -U leda -d mentha > dump_testsNovo.sql
```

âœ… Garante que o ficheiro exportado estÃ¡ em UTF-8 sem BOM antes de reutilizÃ¡-lo ou partilhÃ¡-lo com outros.

ğŸ” Como verificar se o ficheiro estÃ¡ em UTF-8 sem BOM

**No VSCode**:
1. Abre o ficheiro `dump_tests.sql`.
2. No canto inferior direito, verifica a codificaÃ§Ã£o (ex: `UTF-8`, `UTF-16 LE`, etc.).
3. Clica na codificaÃ§Ã£o e, se necessÃ¡rio, converte para `UTF-8`.
4. **Muito importante**: se vires `UTF-8 with BOM`, clica e escolhe **Reopen with Encoding > UTF-8** (sem BOM) e guarda novamente.

**ğŸ”„ Como converter para UTF-8 sem BOM**

**Windows (PowerShell):**

```powershell
Get-Content dump_tests.sql | Set-Content -Encoding utf8 dump_tests_clean.sql
```


### ğŸš€ Ambiente de ProduÃ§Ã£o

A base de dados de produÃ§Ã£o usa um dump especÃ­fico chamado `dump_file.sql`. Este ficheiro contÃ©m dados reais e sensÃ­veis, 

> âš ï¸ Este ficheiro para ser colocado no servidor da lusofona no futuro tem de ser pedido ao professor

#### âœ… Importar dump de produÃ§Ã£o no servidor
Para importar o ficheiro dump_file.sql:

Envia o ficheiro para o servidor (exemplo com SCP):

```bash
scp dump_file.sql root@IP_DO_SERVIDOR:/caminho/do/projeto/
```
Garante que o nome do ficheiro no servidor Ã© exatamente dump_file.sql.

```bash
docker-compose down -v
docker-compose up --build
```
O volume do PostgreSQL serÃ¡ criado ou reescrito, e o dump serÃ¡ carregado automaticamente.

#### ğŸ“¥ Exportar dump da produÃ§Ã£o (Backup)
Para criar um backup da base de dados de produÃ§Ã£o diretamente no servidor:

```
# 1. Acede ao container da base de dados
docker exec -it dbpostgresql bash

# 2. Gera um novo dump com data para organizaÃ§Ã£o
pg_dump -U leda -d mentha > /backups/dump_YYYYMMDD.sql
Substitui YYYYMMDD pela data atual, ex: dump_20250620.sql.
```

#### â¬‡ï¸ Transferir o backup para a tua mÃ¡quina local:
```bash
scp root@IP_DO_SERVIDOR:/backups/dump_20250620.sql ./backups/
```

#### ğŸ“ Pasta de Backups
Por padrÃ£o, a pasta /backups nÃ£o estÃ¡ criada automaticamente, mas Ã© altamente recomendada criar no servido. Esta pasta deve ser usada para:

- Guardar versÃµes anteriores dos dumps (ex: dump_YYYYMMDD.sql)
- Facilitar a recuperaÃ§Ã£o rÃ¡pida da base de dados em caso de falha ou corrupÃ§Ã£o de dados

âš ï¸ Cria esta pasta manualmente se ainda nÃ£o existir:
mkdir backups 


---

## ğŸ–¥ï¸ ConfiguraÃ§Ã£o local do Ambiente de Desenvolvimento 

Esta secÃ§Ã£o detalha o processo completo para configurar o ambiente de desenvolvimento localmente, desde a preparaÃ§Ã£o inicial atÃ© Ã  execuÃ§Ã£o da aplicaÃ§Ã£o localmente, garantindo que todos os serviÃ§os essenciais estÃ£o corretamente configurados e a funcionar.

### 1. Clonar o RepositÃ³rio

- ```git clone https://github.com/MentHA-ULHT/mentha_digital/```

- ```cd <diretorio_do_projeto>```

- ```code .```

![image](https://github.com/user-attachments/assets/f491478c-76ff-4fb3-a57e-04256f589e29)

---

### 2. Preparar os Ficheiros
Certifique-se de que estÃ¡ presente:
-	docker-compose.yml
- dump_file.sql

---

### 3. Criar Ficheiros `.env`
Colocar no ficheiro estas informaÃ§Ãµes:
```
POSTGRES_USER=leda
POSTGRES_PASSWORD=Password pedir grupo whatsApp
POSTGRES_DB=mentha

PGUSER=leda
PGPASSWORD=Password pedir grupo whatsApp
PGDB=mentha

POSTGRES_HOST=dbpostgresql
POSTGRES_PORT=5432
```

---

### 4. Inicializar os ServiÃ§os pela Primeira Vez (um a um)
Este passo Ã© necessÃ¡rio apenas uma vez, para criar e preparar os serviÃ§os. Esta configuraÃ§Ã£o inicial faz o seguinte:
- Cria os containers necessÃ¡rios (base de dados, app Django)
- Importa os dados iniciais da base de dados (dump_file.sql)
- Inicia o servidor de desenvolvimento Django com as aplicaÃ§Ãµes integradas
#### a) Iniciar a base de dados
```docker compose up dbpostgresql```

![image](https://github.com/user-attachments/assets/68ef3362-7c83-468d-873e-6915df994ace)

Isto vai criar e executar o container da base de dados PostgreSQL. Os dados sÃ£o armazenados num volume persistente (chamado postgres_data), que garante que a base de dados mantÃ©m a sua informaÃ§Ã£o mesmo apÃ³s paragens ou reinÃ­cios do container.

#### b) Importar ficheiro SQL
```docker compose up dbpostgresql_init```

![image](https://github.com/user-attachments/assets/9d7f9a1b-7915-4581-810c-824a6f4abddb)

Este Ã© um container temporÃ¡rio que se liga ao container da base de dados e importa o conteÃºdo do dump_file.sql. Este passo sÃ³ Ã© necessÃ¡rio na primeira execuÃ§Ã£o do projeto ou caso queira se dar reset Ã  base de dados.

#### c) Iniciar a aplicaÃ§Ã£o Django
```docker compose up web```

![image](https://github.com/user-attachments/assets/feaade1e-94e6-4a5b-88eb-d6ff4a0bba11)

Este serviÃ§o constrÃ³i a imagem da aplicaÃ§Ã£o Django, instala as dependÃªncias, aplica migraÃ§Ãµes e inicia o servidor de desenvolvimento. Inclui as apps diario, mentha e protocolo.

#### d) Verificar conteiners
No Docker desktop verificar se todos os conteiners foram criados , e verificar se os conteiners dbpostgresql e Web estÃ£o ativos

![image](https://github.com/user-attachments/assets/4a840f02-9d1d-48d2-947c-c9b35582d980)

O container dbpostgresql_init Ã© temporÃ¡rio e termina automaticamente apÃ³s importar os dados.

#### e) Verificar volume

- O volume postgres_data pode ser visualizado no Docker Desktop (seÃ§Ã£o "Volumes").
- Este volume guarda todos os dados da base de dados PostgreSQL e nÃ£o Ã© apagado ao parar os containers, garantindo persistÃªncia entre sessÃµes.

![image](https://github.com/user-attachments/assets/86a4d558-572c-4447-88fa-8aaf4a9e8438)


#### f) Abrir a aplicaÃ§Ã£o no browser

![image](https://github.com/user-attachments/assets/c41c7772-3730-4933-baf7-3c4e4f41ec6a)

Trocar o http por : localhost:8000

![image](https://github.com/user-attachments/assets/e4855d2a-4c9b-4064-ba5c-03c63462dcfa)

Login:
- Username: Ver no Grupo do WhatsApp
- Password: Ver no Grupo do WhatsApp

---

### 5. Inicializar Todos os ServiÃ§os de Uma Vez

Este passo deve ser efetuado sempre para inicializar o website, apÃ³s a primeira vez que se faÃ§a o passo 4, o passo 4 nunca mais volta a ser preciso ser efetuado.

Sempre que se quiser inicializar o website faz -se:

```docker-compose up```

Este comando levanta todos os serviÃ§os de forma automÃ¡tica: base de dados e aplicaÃ§Ã£o Django. A importaÃ§Ã£o do dump_file.sql nÃ£o serÃ¡ repetida, pois o container dbpostgresql_init apenas corre uma vez.

---

### 6. ObservaÃ§Ã£o

O serviÃ§o web estÃ¡ configurado para atualizar ao serem feitas alteraÃ§Ãµes no cÃ³digo, ou seja ao serem feitas alteraÃ§Ãµes ao cÃ³digo basta fazer refresh na pÃ¡gina.

---

### 7. Comandos Ãšteis Adicionais (para Desenvolvimento)

#### Reiniciar Tudo com Build (forÃ§a nova instalaÃ§Ã£o de dependÃªncias, Ãºtil apÃ³s editar o Dockerfile ou requirements.txt)

```docker-compose up â€“build```

#### Limpar Recursos Docker NÃ£o Utilizados

```docker system prune -a```

Este comando:

- Remove todos os containers parados
- Remove todas as imagens nÃ£o utilizadas (nÃ£o referenciadas por nenhum container ativo)
- Remove volumes nÃ£o utilizados
- Liberta espaÃ§o em disco

Uso recomendado:

-	Quando estÃ¡s com problemas de espaÃ§o
-	Quando queres limpar completamente o ambiente Docker
-	ApÃ³s muitos testes e builds antigos

--- 

### ğŸš€ Guia de adaptaÃ§Ã£o da pipeline de Deploy no Servidor (ProduÃ§Ã£o) a uma nova VM
Este guia mostra como ligar a infraestrutura de produÃ§Ã£o a uma nova VM (Ubuntu).

### âœ… 1. PrÃ©-requisitos na Nova VM (Ubuntu)

```
# Atualizar e instalar Docker
sudo apt update && sudo apt install docker.io -y
sudo systemctl enable docker && sudo systemctl start docker

# Instalar Docker Compose v2
sudo curl -L "https://github.com/docker/compose/releases/download/v2.24.6/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
```

### ğŸ” 2. Atualizar Secrets no GitHub
No repositÃ³rio, vai a Settings > Secrets and variables > Actions > Repository secrets e atualiza estes valores:

- **SERVER_HOST** - IP ou domÃ­nio da nova VM
- **SERVER_USER** - Nome do utilizador SSH da VM (ex: root, ubuntu)
- **SERVER_SSH_KEY** - Chave privada SSH (sem password)

âš ï¸ O .env serÃ¡ gerado automaticamente na VM com estes secrets!

### ğŸ“¦ 3. Preparar o Dump Inicial (uma sÃ³ vez)
Como a pipeline nÃ£o envia o dump_file.sql, precisas de o colocar manualmente apenas na primeira vez:
```
# Envia o ficheiro para a VM
scp dump_file.sql user@ip_da_vm:~/mentha_project/
```

### ğŸ“‚ 4. Importar o Dump Manualmente (Primeira Vez)
SÃ³ precisas de fazer isto uma vez na VM nova:

```
# Aceder ao container da base de dados
docker exec -it dbpostgresql bash

# Importar o dump
psql -U leda -d mentha -f /code/dump_file.sql
```

### ğŸ” 5. Reiniciar os ServiÃ§os (sÃ³ se alterares manualmente o dump)
```
cd ~/mentha_project
docker-compose -f compose.prod.yaml down
docker-compose -f compose.prod.yaml up -d --build
```
### ğŸ—ƒï¸ 7. Criar Pasta de Backups
```
cd ~/mentha_project
mkdir backups
mv dump_file.sql backups/
```

--- 

## ğŸŒ Infraestrutura de ProduÃ§Ã£o â€“ Acesso e Contexto
Atualmente, o projeto MentHA Digital encontra-se em dois ambientes distintos em producao:

### ğŸ§ª Ambiente de Staging (VersÃ£o Atualizada e EstÃ¡vel)
A versÃ£o mais recente e funcional do projeto encontra-se alojada numa VM da DigitalOcean.
Este ambiente foi criado para testar o processo de deploy, infraestrutura, CI/CD e validaÃ§Ã£o geral do MVP com dados reais.

âœ… Esta Ã© a versÃ£o mais atualizada do projeto, com deploy automatizado via GitHub Actions e base de dados configurada.

Acesso Ã  plataforma:

- URL: http://menthadigital.pt/
- Credenciais: Ver no Grupo do WhatsApp

### ğŸ›ï¸ Servidor da LusÃ³fona (VersÃ£o Oficial, Desatualizada)
O servidor oficial da Universidade LusÃ³fona estÃ¡ atualmente com uma versÃ£o antiga do projeto.
O objetivo principal para as equipas futuras serÃ¡ migrar a infraestrutura estÃ¡vel da DigitalOcean para este servidor, usando a pipeline de CI/CD existente.
O passo a passo para adptar a pipeline existente Ã¡ VM da LusÃ³fona encontra se explicada

**Dados da VM da LusÃ³fona:**

- **DNS:** jupiter.ulusofona.pt
- **IP:** 193.137.75.199
- **Utilizador:** ***
- **Password:** ***

Acesso Ã  plataforma:

- URL: https://menthadigital.com/
- Credenciais: Ver no Grupo do WhatsApp

---

## ğŸŒ± Workflow de Git

No relatÃ³rio de TFC de 2024/2025 estÃ¡ presente um capÃ­tulo que explica o que workflow que adotamos no git. Este workflow Ã© baseado no mÃ©todo usado em empresas com projetos grandes para evitar problemas de controlo de versÃµes. Ã‰ recomendada a leitura deste capÃ­tulo e utilizaÃ§Ã£o deste workflow.

---

## ğŸ“„ DocumentaÃ§Ã£o

No relatÃ³rio de TFC de 2024/2025 estÃ¡ presente um capÃ­tulo que explica o estilo de documentaÃ§Ã£o utilizado. Ã‰ recomendado a continuidade de utilizaÃ§Ã£o deste estilo de documentaÃ§Ã£o, visto que ajuda bastante no desenvolvimento do projeto.

---

## ğŸ“ ObservaÃ§Ãµes Importantes

### Ficheiro requirements.txt:

Todas as bibliotecas Python utilizadas no projeto devem estar listadas neste ficheiro. Sempre que uma nova biblioteca for instalada (ex: via pip install), Ã© obrigatÃ³rio atualizar o requirements.txt.
Isto garante que o ambiente de produÃ§Ã£o, bem como qualquer outro ambiente de desenvolvimento, possa instalar exatamente as mesmas dependÃªncias do projeto original.

### AlteraÃ§Ãµes gerais ao projeto:

Sempre que forem feitas alteracoes que influenciem este processo de instalaÃ§Ã£o local do projeto , deploy para o servidor , alteraÃ§Ãµes da arquitetura geral do projeto e tecnologias utilizadas este ficheiro deve ser atualizado , para dessa forma o guia de instalaÃ§Ã£o ficar em conformidade com o estado atual do projeto.

