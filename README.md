# üß† MentHA ‚Äì Guia de Instala√ß√£o e Execu√ß√£o 






<img width="1906" height="902" alt="image" src="https://github.com/user-attachments/assets/1286e3cd-10b3-4e46-bb7a-1e9ac8547f2c" />

## üîß Requisitos de Software

- Python 3.11 ou superior  
- Docker e Docker Compose instalados  
- Git instalado  
- Sistema operativo: Linux, macOS ou Windows  

---

## üèóÔ∏è Arquitetura Geral do Projeto

O projeto consiste num website constru√≠do com Django, que integra tr√™s aplica√ß√µes distintas:

- `diario/`: Aplica√ß√£o respons√°vel pelo registo de atividades (integra MentHA COG e MentHA CARE).
- `mentha/`: Website principal do projeto MentHA.
- `protocolo/`: Aplica√ß√£o dedicada √† avalia√ß√£o neuropsicol√≥gica (MentHA EVAL ‚Äì "Protocolo MentHA").

### Diret√≥rio principal:
```
/raiz_do_projeto
‚îú‚îÄ‚îÄ diario/                  # MentHA COG & CARE
‚îú‚îÄ‚îÄ mentha/                 # Frontend principal
‚îú‚îÄ‚îÄ protocolo/              # MentHA EVAL
‚îú‚îÄ‚îÄ gateway/                # Configura√ß√£o NGINX
‚îú‚îÄ‚îÄ manage.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Dockerfile              # Para desenvolvimento
‚îú‚îÄ‚îÄ Dockerfile.prod         # Para produ√ß√£o (Gunicorn)
‚îú‚îÄ‚îÄ compose.yaml            # Docker Compose (dev)
‚îú‚îÄ‚îÄ compose.prod.yaml       # Docker Compose (prod)
‚îú‚îÄ‚îÄ dump_tests.sql          # Dump de testes (dados dummy)
‚îî‚îÄ‚îÄ .env                    # Vari√°veis de ambiente (dev/prod)
```
---

## üîÄ Ambientes do Projeto

O projeto MentHA Digital est√° preparado para funcionar em dois ambientes distintos, com infraestruturas adaptadas a cada caso:

---

## üß™ Ambiente de Desenvolvimento

Este ambiente destina-se a programadores e equipas durante a fase de implementa√ß√£o, testes e valida√ß√£o local da aplica√ß√£o. Permite um ciclo de desenvolvimento r√°pido e seguro, com dados an√≥nimos, hot reload e isolamento completo da produ√ß√£o.

### üê≥ Arquitetura e Servi√ßos Docker

O ambiente √© orquestrado atrav√©s do ficheiro `compose.yaml`, que define tr√™s servi√ßos principais que trabalham em conjunto para simular o funcionamento completo da aplica√ß√£o:

1. **dbpostgresql**  
   - Servi√ßo respons√°vel pela execu√ß√£o da base de dados PostgreSQL.  
   - Utiliza a imagem oficial `postgres:12.9`.  
   - Os dados s√£o armazenados num volume persistente Docker chamado `postgres_data`, garantindo persist√™ncia entre rein√≠cios.

2. **dbpostgresql_init**  
   - Servi√ßo tempor√°rio respons√°vel por importar automaticamente o dump de dados de teste (`dump_tests.sql`) para a base de dados.  
   - Usa a mesma imagem oficial `postgres:12.9`.  
   - Monta o ficheiro `dump_tests.sql` do sistema local para dentro do container, permitindo inicializa√ß√£o com dados an√≥nimos.

3. **web**  
   - Servi√ßo principal que executa a aplica√ß√£o Django.  
   - Constr√≥i a imagem localmente com base no `Dockerfile`.  
   - Aplica automaticamente todas as migra√ß√µes para manter o esquema da base de dados atualizado.  
   - Inicia o servidor de desenvolvimento Django (`runserver`) com suporte a hot reload, facilitando um desenvolvimento √°gil.

### üß† Funcionalidades Adicionais

- **Live Reload (Hot Reload):**  
  O c√≥digo local est√° ligado ao container via volume (`.:/app`). Sempre que alteras ficheiros, o servidor Django reinicia automaticamente, permitindo visualizar as mudan√ßas em tempo real, sem necessidade de reiniciar manualmente.

- **Vari√°veis de Ambiente:**  
  Todas as configura√ß√µes espec√≠ficas do ambiente est√£o definidas no ficheiro `.env`, separado do c√≥digo-fonte. Isto facilita a altera√ß√£o de dados sens√≠veis sem comprometer o c√≥digo.

- **Isolamento da Produ√ß√£o:**  
  O ambiente utiliza um dump de dados an√≥nimos (`dump_tests.sql`), garantindo que os testes locais n√£o interferem nem comprometem dados reais de produ√ß√£o.

- **Debugging Simplificado:**  
  Logs detalhados e compatibilidade com ferramentas como o VSCode Debugger permitem uma dete√ß√£o e resolu√ß√£o de erros mais eficiente.


---

## üöÄ Ambiente de Produ√ß√£o

Este ambiente corresponde √† infraestrutura utilizada para o deploy real da aplica√ß√£o, dispon√≠vel ao p√∫blico. O foco principal √© garantir **seguran√ßa**, **estabilidade**, **performance** e **escalabilidade** para o sistema em produ√ß√£o.

### üèóÔ∏è Vis√£o Geral

O ambiente de produ√ß√£o √© uma configura√ß√£o mais robusta e otimizada, que inclui:

- Execu√ß√£o da aplica√ß√£o Django com um servidor WSGI profissional (Gunicorn) para melhor desempenho e gest√£o de m√∫ltiplos pedidos simult√¢neos.
- Utiliza√ß√£o de um **reverse proxy** (NGINX) containerizado, que serve ficheiros est√°ticos e media de forma eficiente, al√©m de proteger e otimizar as comunica√ß√µes HTTP.
- Base de dados PostgreSQL com armazenamento persistente e saud√°vel.
- Configura√ß√µes espec√≠ficas de ambiente que garantem a separa√ß√£o total da l√≥gica e dados de desenvolvimento.

### üê≥ Docker & Orquestra√ß√£o

O ambiente √© gerido pelo ficheiro `compose.prod.yaml`, que define tr√™s servi√ßos essenciais:

1. **dbpostgresql**  
   - Container da base de dados PostgreSQL, respons√°vel por armazenar todos os dados da aplica√ß√£o.  
   - Usa um volume Docker persistente para garantir que os dados se mant√™m seguros entre rein√≠cios e atualiza√ß√µes do container.  
   - Inclui um mecanismo de healthcheck para monitorar a disponibilidade do servi√ßo.

2. **web**  
   - Servi√ßo principal que executa a aplica√ß√£o Django utilizando o servidor **Gunicorn**, um servidor WSGI leve e eficiente, indicado para produ√ß√£o.  
   - Recebe as requisi√ß√µes encaminhadas pelo NGINX e responde com conte√∫dos din√¢micos da aplica√ß√£o.  
   - Aplica migra√ß√µes e configura√ß√µes otimizadas para o ambiente de produ√ß√£o.  
   - N√£o exp√µe funcionalidades de hot reload, garantindo estabilidade.

3. **nginx**  
   - Reverse proxy containerizado que atua como intermedi√°rio entre os clientes e o servi√ßo Django.  
   - Serve diretamente ficheiros est√°ticos (`/static/`) e media (`/media/`) para otimizar a entrega de conte√∫do e reduzir carga no servidor de aplica√ß√£o.  
   - Aplica headers de seguran√ßa importantes (ex: Content Security Policy, X-Frame-Options) e compress√£o (gzip) para melhorar performance e seguran√ßa.  
   - Encaminha requisi√ß√µes HTTP para o servi√ßo `web` (Gunicorn), mantendo a arquitetura limpa e modular.  

### üîê Seguran√ßa e Boas Pr√°ticas

Para garantir a seguran√ßa da aplica√ß√£o em produ√ß√£o, especialmente em rela√ß√£o √†s credenciais e dados sens√≠veis, adotamos as seguintes pr√°ticas:

- **Vari√°veis de Ambiente para Configura√ß√µes Sens√≠veis**  
  As informa√ß√µes confidenciais, como a `SECRET_KEY` do Django (usada para criptografia interna e prote√ß√£o da sess√£o), as credenciais da base de dados, e outras configura√ß√µes cr√≠ticas, s√£o armazenadas exclusivamente em vari√°veis de ambiente definidas num ficheiro `.env` no servidor de produ√ß√£o.  
  Isto evita que estas chaves sejam inclu√≠das diretamente no c√≥digo-fonte ou no reposit√≥rio Git, protegendo-as de acessos n√£o autorizados e facilitando a sua atualiza√ß√£o sem necessidade de alterar o c√≥digo.

- **Camada de prote√ß√£o via NGINX**  
  O NGINX funciona como reverse proxy e firewall, filtrando requisi√ß√µes maliciosas, aplicando cabe√ßalhos de seguran√ßa HTTP e servindo conte√∫dos est√°ticos, reduzindo a exposi√ß√£o da aplica√ß√£o e melhorando o desempenho.

- **Servidor WSGI profissional (Gunicorn)**  
  O Gunicorn oferece uma gest√£o eficiente das conex√µes, permitindo lidar com m√∫ltiplos pedidos simult√¢neos, garantindo estabilidade e escalabilidade em produ√ß√£o.

---

## üîÅ CI/CD com GitHub Actions

A infraestrutura do projeto est√° totalmente integrada num pipeline automatizado de CI/CD (Continuous Integration / Continuous Deployment) usando o GitHub Actions. Isto permite que, sempre que um c√≥digo novo √© enviado para o reposit√≥rio (push para a branch `main`), todo o processo de testes e deployment seja executado de forma autom√°tica e controlada, garantindo qualidade e rapidez.

### Fluxo do Workflow `deploy.yml`

1. **Fase de Testes (CI)**
   - Cada vez que ocorre um push para a branch principal (`main`), o GitHub Actions inicia uma pipeline de testes.
   - Nesta fase, √© criado um ambiente isolado com um container PostgreSQL tempor√°rio (`mentha_test`) para simular a base de dados durante os testes.
   - A aplica√ß√£o Django executa os seus testes automatizados, validando que todas as funcionalidades principais est√£o corretas e que n√£o existem regress√µes.
   - Apenas se todos os testes forem aprovados, o workflow avan√ßa para a pr√≥xima fase.

2. **Fase de Deploy (CD)**
   - Depois dos testes serem bem sucedidos, a pipeline inicia o deploy autom√°tico da aplica√ß√£o para o servidor remoto.
   - Os ficheiros do projeto s√£o copiados via SCP (Secure Copy Protocol) para o diret√≥rio do servidor destinado ao projeto.
   - O ficheiro `.env` √© gerado dinamicamente no servidor, utilizando segredos (como chaves secretas e credenciais) guardados em seguran√ßa no GitHub Secrets, garantindo que informa√ß√µes sens√≠veis nunca ficam expostas no c√≥digo-fonte p√∫blico.
   - O workflow executa comandos SSH no servidor para:
     - Parar quaisquer servi√ßos Docker em execu√ß√£o (`docker-compose -f compose.prod.yaml down`), garantindo uma atualiza√ß√£o limpa.
     - Recriar e iniciar os servi√ßos em modo destacado, reconstruindo as imagens se necess√°rio (`docker-compose -f compose.prod.yaml up -d --build`).
     - Executar a coleta dos ficheiros est√°ticos da aplica√ß√£o Django (`python manage.py collectstatic --noinput`), preparando-os para serem servidos pelo NGINX.

### Benef√≠cios deste CI/CD automatizado

- **Automa√ß√£o total:** O processo de testes, build e deploy ocorre sem interven√ß√£o manual, reduzindo erros humanos.
- **Seguran√ßa refor√ßada:** As credenciais e segredos ficam guardados de forma segura no GitHub e nunca no reposit√≥rio.
- **Velocidade e fiabilidade:** Permite lan√ßar atualiza√ß√µes rapidamente com menor risco de falhas em produ√ß√£o.
- **Isolamento dos ambientes:** Os testes correm num ambiente separado, evitando interfer√™ncia nos dados reais.

---

## üóÉÔ∏è Bases de Dados 

### üß™ Ambiente de Testes

O ambiente de testes utiliza a base de dados definida no ficheiro `dump_tests.sql`, localizado na raiz do projeto. Este ficheiro cont√©m dados **an√≥nimos ou simulados**, pr√≥prios para desenvolvimento, debugging e testes.

#### ‚úÖ Importar dump de testes

Para carregar um novo dump de testes no ambiente de desenvolvimento:

1. **Substitui** o ficheiro `dump_tests.sql` na raiz do projeto.
2. **Confirma** que est√° codificado em `UTF-8` **sem BOM** (sem Byte Order Mark).
3. **Reinicia os servi√ßos Docker** com remo√ß√£o dos volumes para for√ßar a importa√ß√£o:

```bash
# Apaga volumes antigos e for√ßa importa√ß√£o do novo dump
docker-compose down -v
docker-compose up --build
```
O servi√ßo dbpostgresql_init ir√° executar automaticamente o psql -f dump_tests.sql.

#### üì§ Exportar novo dump de testes

Caso queiras gerar um novo ficheiro `dump_tests.sql` a partir da base de dados atual (por exemplo, para partilhar com colegas), segue os passos abaixo:

```bash
docker exec dbpostgresql pg_dump -U leda -d mentha > dump_testsNovo.sql
```

‚úÖ Garante que o ficheiro exportado est√° em UTF-8 sem BOM antes de reutiliz√°-lo ou partilh√°-lo com outros.

üîé Como verificar se o ficheiro est√° em UTF-8 sem BOM

**No VSCode**:
1. Abre o ficheiro `dump_tests.sql`.
2. No canto inferior direito, verifica a codifica√ß√£o (ex: `UTF-8`, `UTF-16 LE`, etc.).
3. Clica na codifica√ß√£o e, se necess√°rio, converte para `UTF-8`.
4. **Muito importante**: se vires `UTF-8 with BOM`, clica e escolhe **Reopen with Encoding > UTF-8** (sem BOM) e guarda novamente.

**üîÑ Como converter para UTF-8 sem BOM**

**Windows (PowerShell):**

```powershell
Get-Content dump_tests.sql | Set-Content -Encoding utf8 dump_tests_clean.sql
```


### üöÄ Ambiente de Produ√ß√£o

A base de dados de produ√ß√£o usa um dump espec√≠fico chamado `dump_file.sql`. Este ficheiro cont√©m dados reais e sens√≠veis, 

> ‚ö†Ô∏è Este ficheiro para ser colocado no servidor da lusofona no futuro tem de ser pedido ao professor

#### ‚úÖ Importar dump de produ√ß√£o no servidor
Para importar o ficheiro dump_file.sql:

Envia o ficheiro para o servidor (exemplo com SCP):

```bash
scp dump_file.sql root@IP_DO_SERVIDOR:/caminho/do/projeto/
```
Garante que o nome do ficheiro no servidor √© exatamente dump_file.sql.

```bash
docker-compose down -v
docker-compose up --build
```
O volume do PostgreSQL ser√° criado ou reescrito, e o dump ser√° carregado automaticamente.

#### üì• Exportar dump da produ√ß√£o (Backup)
Para criar um backup da base de dados de produ√ß√£o diretamente no servidor:

```
# 1. Acede ao container da base de dados
docker exec -it dbpostgresql bash

# 2. Gera um novo dump com data para organiza√ß√£o
pg_dump -U leda -d mentha > /backups/dump_YYYYMMDD.sql
Substitui YYYYMMDD pela data atual, ex: dump_20250620.sql.
```

#### ‚¨áÔ∏è Transferir o backup para a tua m√°quina local:
```bash
scp root@IP_DO_SERVIDOR:/backups/dump_20250620.sql ./backups/
```

#### üìÅ Pasta de Backups
Por padr√£o, a pasta /backups n√£o est√° criada automaticamente, mas √© altamente recomendada criar no servido. Esta pasta deve ser usada para:

- Guardar vers√µes anteriores dos dumps (ex: dump_YYYYMMDD.sql)
- Facilitar a recupera√ß√£o r√°pida da base de dados em caso de falha ou corrup√ß√£o de dados

‚ö†Ô∏è Cria esta pasta manualmente se ainda n√£o existir:
mkdir backups 


---

## üñ•Ô∏è Configura√ß√£o local do Ambiente de Desenvolvimento 

Esta sec√ß√£o detalha o processo completo para configurar o ambiente de desenvolvimento localmente, desde a prepara√ß√£o inicial at√© √† execu√ß√£o da aplica√ß√£o localmente, garantindo que todos os servi√ßos essenciais est√£o corretamente configurados e a funcionar.

### 1. Clonar o Reposit√≥rio

- ```git clone https://github.com/MentHA-ULHT/mentha_digital/```

- ```cd <diretorio_do_projeto>```

- ```code .```

![image](https://github.com/user-attachments/assets/f491478c-76ff-4fb3-a57e-04256f589e29)

---

### 2. Preparar os Ficheiros
Certifique-se de que est√° presente:
-	docker-compose.yml
- dump_file.sql

---

### 3. Criar Ficheiros `.env`
Colocar no ficheiro estas informa√ß√µes:
```
POSTGRES_USER=leda
POSTGRES_PASSWORD=Password pedir grupo whatsApp
POSTGRES_DB=mentha

PGUSER=leda
PGPASSWORD=Password pedir grupo whatsApp
PGDB=mentha

POSTGRES_HOST=dbpostgresql
POSTGRES_PORT=5432
```

---

### 4. Inicializar os Servi√ßos pela Primeira Vez (um a um)
Este passo √© necess√°rio apenas uma vez, para criar e preparar os servi√ßos. Esta configura√ß√£o inicial faz o seguinte:
- Cria os containers necess√°rios (base de dados, app Django)
- Importa os dados iniciais da base de dados (dump_file.sql)
- Inicia o servidor de desenvolvimento Django com as aplica√ß√µes integradas
#### a) Iniciar a base de dados
```docker compose up dbpostgresql```

![image](https://github.com/user-attachments/assets/68ef3362-7c83-468d-873e-6915df994ace)

Isto vai criar e executar o container da base de dados PostgreSQL. Os dados s√£o armazenados num volume persistente (chamado postgres_data), que garante que a base de dados mant√©m a sua informa√ß√£o mesmo ap√≥s paragens ou rein√≠cios do container.

#### b) Importar ficheiro SQL
```docker compose up dbpostgresql_init```

![image](https://github.com/user-attachments/assets/9d7f9a1b-7915-4581-810c-824a6f4abddb)

Este √© um container tempor√°rio que se liga ao container da base de dados e importa o conte√∫do do dump_file.sql. Este passo s√≥ √© necess√°rio na primeira execu√ß√£o do projeto ou caso queira se dar reset √† base de dados.

#### c) Iniciar a aplica√ß√£o Django
```docker compose up web```

![image](https://github.com/user-attachments/assets/feaade1e-94e6-4a5b-88eb-d6ff4a0bba11)

Este servi√ßo constr√≥i a imagem da aplica√ß√£o Django, instala as depend√™ncias, aplica migra√ß√µes e inicia o servidor de desenvolvimento. Inclui as apps diario, mentha e protocolo.

#### d) Verificar conteiners
No Docker desktop verificar se todos os conteiners foram criados , e verificar se os conteiners dbpostgresql e Web est√£o ativos

![image](https://github.com/user-attachments/assets/4a840f02-9d1d-48d2-947c-c9b35582d980)

O container dbpostgresql_init √© tempor√°rio e termina automaticamente ap√≥s importar os dados.

#### e) Verificar volume

- O volume postgres_data pode ser visualizado no Docker Desktop (se√ß√£o "Volumes").
- Este volume guarda todos os dados da base de dados PostgreSQL e n√£o √© apagado ao parar os containers, garantindo persist√™ncia entre sess√µes.

![image](https://github.com/user-attachments/assets/86a4d558-572c-4447-88fa-8aaf4a9e8438)


#### f) Abrir a aplica√ß√£o no browser

![image](https://github.com/user-attachments/assets/c41c7772-3730-4933-baf7-3c4e4f41ec6a)

Trocar o http por : localhost:8000

![image](https://github.com/user-attachments/assets/e4855d2a-4c9b-4064-ba5c-03c63462dcfa)

Login:
- Username: Ver no Grupo do WhatsApp
- Password: Ver no Grupo do WhatsApp

---

### 5. Inicializar Todos os Servi√ßos de Uma Vez

Este passo deve ser efetuado sempre para inicializar o website, ap√≥s a primeira vez que se fa√ßa o passo 4, o passo 4 nunca mais volta a ser preciso ser efetuado.

Sempre que se quiser inicializar o website faz -se:

```docker-compose up```

Este comando levanta todos os servi√ßos de forma autom√°tica: base de dados e aplica√ß√£o Django. A importa√ß√£o do dump_file.sql n√£o ser√° repetida, pois o container dbpostgresql_init apenas corre uma vez.

---

### 6. Observa√ß√£o

O servi√ßo web est√° configurado para atualizar ao serem feitas altera√ß√µes no c√≥digo, ou seja ao serem feitas altera√ß√µes ao c√≥digo basta fazer refresh na p√°gina.

---

### 7. Comandos √öteis Adicionais (para Desenvolvimento)

#### Reiniciar Tudo com Build (for√ßa nova instala√ß√£o de depend√™ncias, √∫til ap√≥s editar o Dockerfile ou requirements.txt)

```docker-compose up ‚Äìbuild```

#### Limpar Recursos Docker N√£o Utilizados

```docker system prune -a```

Este comando:

- Remove todos os containers parados
- Remove todas as imagens n√£o utilizadas (n√£o referenciadas por nenhum container ativo)
- Remove volumes n√£o utilizados
- Liberta espa√ßo em disco

Uso recomendado:

-	Quando est√°s com problemas de espa√ßo
-	Quando queres limpar completamente o ambiente Docker
-	Ap√≥s muitos testes e builds antigos

--- 

### üöÄ Guia de adapta√ß√£o da pipeline de Deploy no Servidor (Produ√ß√£o) a uma nova VM
Este guia mostra como ligar a infraestrutura de produ√ß√£o a uma nova VM (Ubuntu).

### ‚úÖ 1. Pr√©-requisitos na Nova VM (Ubuntu)

```
# Atualizar e instalar Docker
sudo apt update && sudo apt install docker.io -y
sudo systemctl enable docker && sudo systemctl start docker

# Instalar Docker Compose v2
sudo curl -L "https://github.com/docker/compose/releases/download/v2.24.6/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
```

### üîê 2. Atualizar Secrets no GitHub
No reposit√≥rio, vai a Settings > Secrets and variables > Actions > Repository secrets e atualiza estes valores:

- **SERVER_HOST** - IP ou dom√≠nio da nova VM
- **SERVER_USER** - Nome do utilizador SSH da VM (ex: root, ubuntu)
- **SERVER_SSH_KEY** - Chave privada SSH (sem password)

‚ö†Ô∏è O .env ser√° gerado automaticamente na VM com estes secrets!

### üì¶ 3. Preparar o Dump Inicial (uma s√≥ vez)
Como a pipeline n√£o envia o dump_file.sql, precisas de o colocar manualmente apenas na primeira vez:
```
# Envia o ficheiro para a VM
scp dump_file.sql user@ip_da_vm:~/mentha_project/
```

### üìÇ 4. Importar o Dump Manualmente (Primeira Vez)
S√≥ precisas de fazer isto uma vez na VM nova:

```
# Aceder ao container da base de dados
docker exec -it dbpostgresql bash

# Importar o dump
psql -U leda -d mentha -f /code/dump_file.sql
```

### üîÅ 5. Reiniciar os Servi√ßos (s√≥ se alterares manualmente o dump)
```
cd ~/mentha_project
docker-compose -f compose.prod.yaml down
docker-compose -f compose.prod.yaml up -d --build
```
### üóÉÔ∏è 7. Criar Pasta de Backups
```
cd ~/mentha_project
mkdir backups
mv dump_file.sql backups/
```

--- 

## üåç Infraestrutura de Produ√ß√£o ‚Äì Acesso e Contexto
Atualmente, o projeto MentHA Digital encontra-se em dois ambientes distintos em producao:

### üß™ Ambiente de Staging (Vers√£o Atualizada e Est√°vel)
A vers√£o mais recente e funcional do projeto encontra-se alojada numa VM da DigitalOcean.
Este ambiente foi criado para testar o processo de deploy, infraestrutura, CI/CD e valida√ß√£o geral do MVP com dados reais.

‚úÖ Esta √© a vers√£o mais atualizada do projeto, com deploy automatizado via GitHub Actions e base de dados configurada.

Acesso √† plataforma:

- URL: http://menthadigital.pt/
- Credenciais: Ver no Grupo do WhatsApp

### üèõÔ∏è Servidor da Lus√≥fona (Vers√£o Oficial, Desatualizada)
O servidor oficial da Universidade Lus√≥fona est√° atualmente com uma vers√£o antiga do projeto.
O objetivo principal para as equipas futuras ser√° migrar a infraestrutura est√°vel da DigitalOcean para este servidor, usando a pipeline de CI/CD existente.
O passo a passo para adptar a pipeline existente √° VM da Lus√≥fona encontra se explicada

**Dados da VM da Lus√≥fona:**

- **DNS:** jupiter.ulusofona.pt
- **IP:** 193.137.75.199
- **Utilizador:** ***
- **Password:** ***

Acesso √† plataforma:

- URL: https://menthadigital.com/
- Credenciais: Ver no Grupo do WhatsApp

---

## üå± Workflow de Git

No relat√≥rio de TFC de 2024/2025 est√° presente um cap√≠tulo que explica o que workflow que adotamos no git. Este workflow √© baseado no m√©todo usado em empresas com projetos grandes para evitar problemas de controlo de vers√µes. √â recomendada a leitura deste cap√≠tulo e utiliza√ß√£o deste workflow.

---

## üìÑ Documenta√ß√£o

No relat√≥rio de TFC de 2024/2025 est√° presente um cap√≠tulo que explica o estilo de documenta√ß√£o utilizado. √â recomendado a continuidade de utiliza√ß√£o deste estilo de documenta√ß√£o, visto que ajuda bastante no desenvolvimento do projeto.

---

## üìù Observa√ß√µes Importantes

### Ficheiro requirements.txt:

Todas as bibliotecas Python utilizadas no projeto devem estar listadas neste ficheiro. Sempre que uma nova biblioteca for instalada (ex: via pip install), √© obrigat√≥rio atualizar o requirements.txt.
Isto garante que o ambiente de produ√ß√£o, bem como qualquer outro ambiente de desenvolvimento, possa instalar exatamente as mesmas depend√™ncias do projeto original.

### Altera√ß√µes gerais ao projeto:

Sempre que forem feitas alteracoes que influenciem este processo de instala√ß√£o local do projeto , deploy para o servidor , altera√ß√µes da arquitetura geral do projeto e tecnologias utilizadas este ficheiro deve ser atualizado , para dessa forma o guia de instala√ß√£o ficar em conformidade com o estado atual do projeto.

